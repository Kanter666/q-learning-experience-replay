{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer\n",
    "\n",
    "EPS = float(np.finfo(np.float32).eps)\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.envs.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_hidden=128):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's instantiate and test if it works\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1234)\n",
    "model = QNetwork(num_hidden)\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "test_model = nn.Sequential(\n",
    "    nn.Linear(4, num_hidden), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(num_hidden, 2)\n",
    ")\n",
    "\n",
    "x = torch.rand(10, 4)\n",
    "\n",
    "# If you do not need backpropagation, wrap the computation in the torch.no_grad() context\n",
    "# This saves time and memory, and PyTorch complaints when converting to numpy\n",
    "with torch.no_grad():\n",
    "    assert np.allclose(model(x).numpy(), test_model(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class NoneMemory:\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, transition):\n",
    "        # YOUR CODE HERE\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # YOUR CODE HERE\n",
    "        index = np.random.choice(len(self), batch_size, replace=False)\n",
    "        return [self.memory[i] for i in index]\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # YOUR CODE HERE\n",
    "        return self.memory[-batch_size:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "class UniformMemory:\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, transition):\n",
    "        # YOUR CODE HERE\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # YOUR CODE HERE\n",
    "        index = np.random.choice(len(self), batch_size, replace=False)\n",
    "        return [self.memory[i] for i in index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SumTree(object):\n",
    "    \"\"\"\n",
    "    This SumTree code is modified version of Morvan Zhou: \n",
    "    https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/5.2_Prioritized_Replay_DQN/RL_brain.py\n",
    "    \"\"\"\n",
    "    data_pointer = 0\n",
    "    \n",
    "    \"\"\"\n",
    "    Here we initialize the tree with all nodes = 0, and initialize the data with all values = 0\n",
    "    \"\"\"\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity # Number of leaf nodes (final nodes) that contains experiences\n",
    "        \n",
    "        # Generate the tree with all nodes values = 0\n",
    "        # To understand this calculation (2 * capacity - 1) look at the schema above\n",
    "        # Remember we are in a binary node (each node has max 2 children) so 2x size of leaf (capacity) - 1 (root node)\n",
    "        # Parent nodes = capacity - 1\n",
    "        # Leaf nodes = capacity\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        \n",
    "        \"\"\" tree:\n",
    "            0\n",
    "           / \\\n",
    "          0   0\n",
    "         / \\ / \\\n",
    "        0  0 0  0  [Size: capacity] it's at this line that there is the priorities score (aka pi)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Contains the experiences (so the size of data is capacity)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Here we add our priority score in the sumtree leaf and add the experience in data\n",
    "    \"\"\"\n",
    "    def add(self, priority, data):\n",
    "        # Look at what index we want to put the experience\n",
    "        tree_index = self.data_pointer + self.capacity - 1\n",
    "        \n",
    "        \"\"\" tree:\n",
    "            0\n",
    "           / \\\n",
    "          0   0\n",
    "         / \\ / \\\n",
    "tree_index  0 0  0  We fill the leaves from left to right\n",
    "        \"\"\"\n",
    "        \n",
    "        # Update data frame\n",
    "        self.data[self.data_pointer] = data\n",
    "        \n",
    "        # Update the leaf\n",
    "        self.update (tree_index, priority)\n",
    "        \n",
    "        # Add 1 to data_pointer\n",
    "        self.data_pointer += 1\n",
    "        \n",
    "        if self.data_pointer >= self.capacity:  # If we're above the capacity, you go back to first index (we overwrite)\n",
    "            self.data_pointer = 0\n",
    "            \n",
    "    \n",
    "    \"\"\"\n",
    "    Update the leaf priority score and propagate the change through tree\n",
    "    \"\"\"\n",
    "    def update(self, tree_index, priority):\n",
    "        # Change = new priority score - former priority score\n",
    "        change = priority - self.tree[tree_index]\n",
    "        self.tree[tree_index] = priority\n",
    "        \n",
    "        # then propagate the change through tree\n",
    "        while tree_index != 0:    # this method is faster than the recursive loop in the reference code\n",
    "            \n",
    "            \"\"\"\n",
    "            Here we want to access the line above\n",
    "            THE NUMBERS IN THIS TREE ARE THE INDEXES NOT THE PRIORITY VALUES\n",
    "            \n",
    "                0\n",
    "               / \\\n",
    "              1   2\n",
    "             / \\ / \\\n",
    "            3  4 5  [6] \n",
    "            \n",
    "            If we are in leaf at index 6, we updated the priority score\n",
    "            We need then to update index 2 node\n",
    "            So tree_index = (tree_index - 1) // 2\n",
    "            tree_index = (6-1)//2\n",
    "            tree_index = 2 (because // round the result)\n",
    "            \"\"\"\n",
    "            tree_index = (tree_index - 1) // 2\n",
    "            self.tree[tree_index] += change\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Here we get the leaf_index, priority value of that leaf and experience associated with that index\n",
    "    \"\"\"\n",
    "    def get_leaf(self, v):\n",
    "        \"\"\"\n",
    "        Tree structure and array storage:\n",
    "        Tree index:\n",
    "             0         -> storing priority sum\n",
    "            / \\\n",
    "          1     2\n",
    "         / \\   / \\\n",
    "        3   4 5   6    -> storing priority for experiences\n",
    "        Array type for storing:\n",
    "        [0,1,2,3,4,5,6]\n",
    "        \"\"\"\n",
    "        parent_index = 0\n",
    "        \n",
    "        while True: # the while loop is faster than the method in the reference code\n",
    "            left_child_index = 2 * parent_index + 1\n",
    "            right_child_index = left_child_index + 1\n",
    "            \n",
    "            # If we reach bottom, end the search\n",
    "            if left_child_index >= len(self.tree):\n",
    "                leaf_index = parent_index\n",
    "                break\n",
    "            \n",
    "            else: # downward search, always search for a higher priority node\n",
    "                \n",
    "                if v <= self.tree[left_child_index]:\n",
    "                    parent_index = left_child_index\n",
    "                    \n",
    "                else:\n",
    "                    v -= self.tree[left_child_index]\n",
    "                    parent_index = right_child_index\n",
    "            \n",
    "        data_index = leaf_index - self.capacity + 1\n",
    "\n",
    "        return leaf_index, self.tree[leaf_index], self.data[data_index]\n",
    "    \n",
    "    @property\n",
    "    def total_priority(self):\n",
    "        return self.tree[0] # Returns the root node\n",
    "\n",
    "    \n",
    "class PrioritizedMemory(object):  # stored as ( s, a, r, s_ ) in SumTree\n",
    "    \"\"\"\n",
    "    This SumTree code is modified version and the original code is from:\n",
    "    https://github.com/jaara/AI-blog/blob/master/Seaquest-DDQN-PER.py\n",
    "    \"\"\"\n",
    "    PER_e = 0.01  # Hyperparameter that we use to avoid some experiences to have 0 probability of being taken\n",
    "    PER_a = 0.6  # Hyperparameter that we use to make a tradeoff between taking only exp with high priority and sampling randomly\n",
    "    PER_b = 0.4  # importance-sampling, from initial value increasing to 1\n",
    "    \n",
    "    PER_b_increment_per_sampling = 0.001\n",
    "    \n",
    "    absolute_error_upper = 1.  # clipped abs error\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        # Making the tree \n",
    "        \"\"\"\n",
    "        Remember that our tree is composed of a sum tree that contains the priority scores at his leaf\n",
    "        And also a data array\n",
    "        We don't use deque because it means that at each timestep our experiences change index by one.\n",
    "        We prefer to use a simple array and to overwrite when the memory is full.\n",
    "        \"\"\"\n",
    "        self.tree = SumTree(capacity)\n",
    "        \n",
    "    \"\"\"\n",
    "    Store a new experience in our tree\n",
    "    Each new experience have a score of max_prority (it will be then improved when we use this exp to train our DDQN)\n",
    "    \"\"\"\n",
    "    def push(self, experience):\n",
    "        # Find the max priority\n",
    "        max_priority = np.max(self.tree.tree[-self.tree.capacity:])\n",
    "        \n",
    "        # If the max priority = 0 we can't put priority = 0 since this exp will never have a chance to be selected\n",
    "        # So we use a minimum priority\n",
    "        if max_priority == 0:\n",
    "            max_priority = self.absolute_error_upper\n",
    "        \n",
    "        self.tree.add(max_priority, experience)   # set the max p for new p\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    - First, to sample a minibatch of k size, the range [0, priority_total] is / into k ranges.\n",
    "    - Then a value is uniformly sampled from each range\n",
    "    - We search in the sumtree, the experience where priority score correspond to sample values are retrieved from.\n",
    "    - Then, we calculate IS weights for each minibatch element\n",
    "    \"\"\"\n",
    "    def sample(self, n):\n",
    "        # Create a sample array that will contains the minibatch\n",
    "        memory_b = []\n",
    "        \n",
    "        b_idx, b_ISWeights = np.empty((n,), dtype=np.int32), np.empty((n, 1), dtype=np.float32)\n",
    "        \n",
    "        # Calculate the priority segment\n",
    "        # Here, as explained in the paper, we divide the Range[0, ptotal] into n ranges\n",
    "        priority_segment = self.tree.total_priority / n       # priority segment\n",
    "    \n",
    "        # Here we increasing the PER_b each time we sample a new minibatch\n",
    "        self.PER_b = np.min([1., self.PER_b + self.PER_b_increment_per_sampling])  # max = 1\n",
    "        \n",
    "        # Calculating the max_weight\n",
    "        p_min = np.min(self.tree.tree[-self.tree.capacity:]) / self.tree.total_priority\n",
    "        max_weight = (p_min * n) ** (-self.PER_b)\n",
    "        \n",
    "        for i in range(n):\n",
    "            \"\"\"\n",
    "            A value is uniformly sample from each range\n",
    "            \"\"\"\n",
    "            a, b = priority_segment * i, priority_segment * (i + 1)\n",
    "            value = np.random.uniform(a, b)\n",
    "            \n",
    "            \"\"\"\n",
    "            Experience that correspond to each value is retrieved\n",
    "            \"\"\"\n",
    "            index, priority, data = self.tree.get_leaf(value)\n",
    "            \n",
    "            #P(j)\n",
    "            sampling_probabilities = priority / self.tree.total_priority\n",
    "            \n",
    "            #  IS = (1/N * 1/P(i))**b /max wi == (N*P(i))**-b  /max wi\n",
    "            b_ISWeights[i, 0] = np.power(n * sampling_probabilities, -self.PER_b)/ max_weight\n",
    "                                   \n",
    "            b_idx[i]= index\n",
    "            \n",
    "            experience = [data]\n",
    "            \n",
    "            memory_b.append(experience)\n",
    "        \n",
    "        return b_idx, memory_b, b_ISWeights\n",
    "    \n",
    "    \"\"\"\n",
    "    Update the priorities on the tree\n",
    "    \"\"\"\n",
    "    def batch_update(self, tree_idx, abs_errors):\n",
    "        abs_errors += self.PER_e  # convert to abs and avoid 0\n",
    "        clipped_errors = np.minimum(abs_errors, self.absolute_error_upper)\n",
    "        ps = np.power(clipped_errors, self.PER_a)\n",
    "\n",
    "        for ti, p in zip(tree_idx, ps):\n",
    "            self.tree.update(ti, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([ 0.02295733,  0.02183008,  0.00092248,  0.02490857]), 0, 1.0, array([ 0.02339393, -0.17330509,  0.00142065,  0.3178824 ]), False)]\n"
     ]
    }
   ],
   "source": [
    "capacity = 10\n",
    "memory = NoneMemory(capacity)\n",
    "\n",
    "# Sample a transition\n",
    "s = env.reset()\n",
    "a = env.action_space.sample()\n",
    "s_next, r, done, _ = env.step(a)\n",
    "\n",
    "# Push a transition\n",
    "memory.push((s, a, r, s_next, done))\n",
    "\n",
    "# Sample a batch size of 1\n",
    "print(memory.sample(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1177209b0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116fef438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_epsilon(it):\n",
    "    # YOUR CODE HERE\n",
    "    if it == 0:\n",
    "        return 1\n",
    "    return np.maximum(1 - it/1000, 0.05)\n",
    "\n",
    "# So what's an easy way to check?\n",
    "plt.plot([get_epsilon(it) for it in range(5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def select_action(model, state, epsilon):\n",
    "    # YOUR CODE HERE\n",
    "    with torch.no_grad():\n",
    "        actionProbs = model(torch.Tensor(state)).numpy()\n",
    "    action = np.random.choice(len(actionProbs), 1) if np.random.rand() < epsilon else np.argmax(actionProbs)\n",
    "    return int(action.squeeze())\n",
    "\n",
    "s = env.reset()\n",
    "a = select_action(model, s, 0.05)\n",
    "assert not torch.is_tensor(a)\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_q_val(model, state, action):\n",
    "    # YOUR CODE HERE\n",
    "    return torch.gather(model(state), 1, action.unsqueeze(1)).squeeze()\n",
    "    \n",
    "def compute_target(model, reward, next_state, done, discount_factor):\n",
    "    # done is a boolean (vector) that indicates if next_state is terminal (episode is done)\n",
    "    # YOUR CODE HERE\n",
    "    x = reward * done.to(torch.float)\n",
    "    notdone = (done + 1) % 2\n",
    "    maxV, maxA = torch.max(model(next_state), 1)\n",
    "    y = (reward + discount_factor * maxV) * notdone.to(torch.float)\n",
    "    return x + y\n",
    "\n",
    "def train(model, memory, optimizer, batch_size, discount_factor):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "    \n",
    "    # don't learn without some decent experience\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "\n",
    "    # random transition batch is taken from experience replay memory\n",
    "    transitions = memory.sample(batch_size)\n",
    "    \n",
    "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
    "    state, action, reward, next_state, done = zip(*transitions)\n",
    "    \n",
    "    # convert to PyTorch and define types\n",
    "    state = torch.tensor(state, dtype=torch.float)\n",
    "    action = torch.tensor(action, dtype=torch.int64)  # Need 64 bit to use them as index\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float)\n",
    "    reward = torch.tensor(reward, dtype=torch.float)\n",
    "    done = torch.tensor(done, dtype=torch.uint8)  # Boolean\n",
    "    \n",
    "    # compute the q value\n",
    "    q_val = compute_q_val(model, state, action)\n",
    "    \n",
    "    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n",
    "        target = compute_target(model, reward, next_state, done, discount_factor)\n",
    "    \n",
    "    # loss is measured from error between current and newly expected Q values\n",
    "    loss = F.smooth_l1_loss(q_val, target)\n",
    "\n",
    "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()  # Returns a Python scalar, and releases history (similar to .detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ReplayMemory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8a7b15fa2a0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# We need a larger memory, fill with dummy data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtransition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReplayMemory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ReplayMemory' is not defined"
     ]
    }
   ],
   "source": [
    "# You may want to test your functions individually, but after you do so lets see if the method train works.\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "# Simple gradient descent may take long, so we will use Adam\n",
    "optimizer = optim.Adam(model.parameters(), learn_rate)\n",
    "\n",
    "# We need a larger memory, fill with dummy data\n",
    "transition = memory.sample(1)[0]\n",
    "memory = ReplayMemory(10 * batch_size)\n",
    "for i in range(batch_size):\n",
    "    memory.push(transition)\n",
    "\n",
    "# Now let's see if it works\n",
    "loss = train(model, memory, optimizer, batch_size, discount_factor)\n",
    "\n",
    "print (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def run_episodes(train, model, memory, env, num_episodes, batch_size, discount_factor, learn_rate):\n",
    "    optimizer = optim.Adam(model.parameters(), learn_rate)\n",
    "\n",
    "    durations = torch.zeros(num_episodes)\n",
    "    iteration = 0\n",
    "\n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            a = select_action(model, s, get_epsilon(iteration))\n",
    "            s_next, r, done, _ = env.step(a)\n",
    "            transition = (s, a, r, s_next, done)\n",
    "            memory.push(transition)\n",
    "            s = s_next\n",
    "            train(model, memory, optimizer, batch_size, discount_factor)\n",
    "            durations[episode] += 1\n",
    "            iteration += 1\n",
    "\n",
    "    return durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(er_type='uniform'):\n",
    "    # Let's run it!\n",
    "    num_episodes = 100\n",
    "    batch_size = 64\n",
    "    discount_factor = 0.8\n",
    "    learn_rate = 1e-3\n",
    "    \n",
    "    er_types = {\n",
    "        'none': NoneMemory,\n",
    "        'uniform': UniformMemory,\n",
    "        'prioritized': PrioritizedMemory\n",
    "    }\n",
    "\n",
    "    memory = er_types[er_type](10000)\n",
    "    num_hidden = 128\n",
    "    seed = 42  # This is not randomly chosen\n",
    "\n",
    "    # We will seed the algorithm (before initializing QNetwork!) for reproducability\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    env.seed(seed)\n",
    "\n",
    "    model = QNetwork(num_hidden)\n",
    "\n",
    "    episode_durations = run_episodes(train, model, memory, env, num_episodes, batch_size, discount_factor, learn_rate)\n",
    "    return episode_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.25it/s]\n",
      "100%|██████████| 100/100 [00:06<00:00, 14.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11786a208>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd8VGXWwPHfSW8ESAECAZLQewtNRVBULCjKotgQ14K6\nrrqua9vyqqvsuru+9lddd1XsioqKXToKCITeIUAgoaQ3ElLnef+4E5iEhISUuZPkfD+ffCZz7517\nz0wmZ54597nPI8YYlFJKtVxedgeglFKqaWmiV0qpFk4TvVJKtXCa6JVSqoXTRK+UUi2cJnqllGrh\nNNG3QiLynYjMbOR9Pi4i7zXSvuaIyFONsa86Hu8GEfnRXcfzdCJyTETiGnmfS0Xktsbcp6o7H7sD\nUPUjIklAR6DcZfEcY8xva3usMeaSporL04lIDLAf8DXGlAEYY94H3rcxLI9ijAmxOwbVuDTRN2+X\nG2MW2h2EJxERb2NMee1btgwi4lPxgaVUTbR00wKJyM0iskJEXhaRXBHZKSITXdaf+BotIj1FZJlz\nuwwR+dhlu7NEZK1z3VoROctlXazzcfkisgCIqBLDGBFZKSI5IrJJRCacJt5hIrLeua+PgYAqz+Xn\nKtsbEenp/H2OiLwqIt+KSAFwnohcJiIbRCRPRJJF5HGXhy933uY4SxRjqx6jlue9VESedL6++SLy\no4hEONcFiMh7IpLpfN5rRaRjDc85SUQeFZHtIpItIm+JiOvzniwiG537WSkig6s89mER2QwUiMgp\nDTYR6SsiC0QkS0R2icg1LuvmiMhrzvX5zr9j9xpe30udMeaLyCER+YPLdreLSKLzGPNFpLPLugud\n77tcEXkZkCrx3SIiO5zP/QfX46smYIzRn2b4AyQBF9Sw7magDLgf8AWmA7lAmHP9UuA25+8fAn/C\n+tAPAM5xLg8DsoEZWN/8rnPeD3euXwU8C/gD5wL5wHvOdV2ATOBS534vdN6PrCZWP+CAS6zTgFLg\nKZfn8nOVxxigp/P3Oc7ndrbLc5gADHLeHwykAlc6t49xPt6nyuv1cx2f91JgL9AbCHTef9q57g7g\nKyAI8AZGAKGn+fttBbo6j7nC5TkPA9KA0c79zHRu7+/y2I3OxwZWs+9gIBn4tfM5DAMygP4ur1m+\n8+/mD7zg+hpXeX2PAOOcv7cHhjt/P9+5z+HOfbwELHeui3Duf5rzb3o/1vux4j03BUgE+jnj+zOw\n0u7/qZb8oy365u0LZ4uv4ud2l3VpwPPGmFJjzMfALuCyavZRCnQHOhtjiowxFS3by4A9xph3jTFl\nxpgPgZ3A5SLSDRgJ/MUYU2yMWY6V4CrcCHxrjPnWGOMwxiwAErASf1VjsJJBRayfAmvP8HX40hiz\nwnmsImPMUmPMFuf9zVgfZuPruK8an7fLNm8ZY3YbY44Dc4GhzuWlQDhWkiw3xqwzxuSd5lgvG2OS\njTFZwGysDxWAWcC/jTGrnft5GyjGeq0qvOh87PFq9jsZSDLGvOV8DhuAz4CrXbb5xhiz3BhTjPVB\nP1ZEulazr1Kgv4iEGmOyjTHrnctvAN40xqx37uNR5z5isP7O24wxnxpjSoHngaMu+7wT+LsxZoex\nyk5/A4Zqq77paKJv3q40xrRz+fmPy7pDxhjXEesOAJ051UNYX6vXiMg2EbnFubyz8zGuDmC11jsD\n2caYgirrKnQHrnb9EALOAaKqOX7nGmI9E8mud0RktIgsEZF0EcnFSiwR1T+02nhqet4VXJNWIVBx\n8vJd4AfgIxE5LCL/FBHfOsbt+vfpDjxQ5fXrSuW/X6XnXEV3YHSVx98AdKru8caYY0AW1b8/foWV\nuA84SzxjncsrvU7OfWRy8v3hun9TJd7uwAsusWVhvQddX2PViDTRt1xdRMS1LtoNOFx1I2PMUWPM\n7caYzlilh1ec9dnDWP+QVNnHIayv8+1FJLjKugrJwLtVPoSCjTFPVxPnkRpirVCAVQoBQERck9WJ\np1Hl/gfAfKCrMaYt8Bona8S1Ddd6uud9Ws5vJE8YY/oDZ2G1rG86zUNcW9Cuf59kYHaV1y/I+e3i\nxOFOs99kYFmVx4cYY+6q7tgiEoJVPqru/bHWGDMF6AB8gfUNBqq8Ts73Qjgn3x+u+5cqzzUZuKNK\nfIHGmJWneU6qATTRt1wdgHtFxFdErsaqh35bdSMRuVpEop13s7ESiMO5bW8RuV5EfERkOtAf+NoY\ncwCrFPOEiPiJyDlULm28h1XimSQi3s6TlBNcjuNqFVb9tiLWqcAol/WbgAEiMtR5svLxOjz3NkCW\nMaZIREYB17usS3c+v5r6idf4vGs7qIicJyKDRMQbyMMqezhO85C7RSRaRMKwyicVJ8L/A9zp/GYi\nIhIs1gnmNrXF4PS18znMcL6mviIyUkT6uWxzqYicIyJ+wJPAL8aYqt+M/MS6xqCtswST5/J8PgR+\n7fy7+GOVX1YbY5KAb7D+ZlPFOlF8L5W/TbwGPCoiA5zHaet8j6omoom+eftKrJ4jFT+fu6xbDfTC\nOmE2G5hmjMmsZh8jgdUicgyrFXyfMWafc9vJwANYX8kfAiYbYzKcj7se62RhFvAY8E7FDp0JYwrw\nR6zEmgw8SDXvN2NMCTAV64RoFtaJ43ku63cDfwUWAnuAn6vuoxq/Af4qIvnA/3CyFYoxptD5eqxw\nlg5c697U4XmfTifgU6yEuANYhlXOqckHwI/APqwTvE85Y0gAbgdexvrwTcR6ferEGJMPXARci9Xy\nPgr8A+ukqeuxH8N6zUdgnVepzgwgSUTysEpgNziPsRD4C1bt/wjQw3k8nK/V1cDTWK9hL6yTzRXx\nfe6M5yPnfrcCrfbaDneQyqVR1RKIyM1YPRzOsTsWVT2xLni7zdhwHYSIzAFSjDF/dvexlT20Ra+U\nUi2cJnqllGrhtHSjlFItnLbolVKqhfOIQc0iIiJMTEyM3WEopVSzsm7dugxjTGRt23lEoo+JiSEh\nIcHuMJRSqlkRkTpdRa6lG6WUauE00SulVAuniV4ppVo4j6jRV6e0tJSUlBSKiorsDqVVCAgIIDo6\nGl/f0w22qJRqjjw20aekpNCmTRtiYmKoPLChamzGGDIzM0lJSSE2NtbucJRSjcxjSzdFRUWEh4dr\nkncDESE8PFy/PSnVQnlsogc0ybuRvtZKtVweW7pRSqlalR6HDe9BYHvoOBDCe4K3prWqPLpFbzcR\n4YEHHjhx/5lnnuHxxx+v8+PnzJlDZGQkQ4cOPfGzfft2kpKSCAwMZOjQofTv35+bbrqJ0tLSJngG\nSrVgxcfg/avh2z/AZ7fCK6Ph713gs9ugoC7TB7QemuhPw9/fn3nz5pGRUf83zfTp09m4ceOJn/79\n+wPQo0cPNm7cyJYtW0hJSWHu3Lm17EkpdUJRLrx7FRxYCVe+BneugKv+DcNmwLYv4P9GW7cK0NLN\nafn4+DBr1iyee+45Zs+eXWldUlISt9xyCxkZGURGRvLWW2/RrVu3GvZUM29vb0aNGsWhQ7VOSapU\ny1deCvuWwfbPIWkFOMpPrmvbxSrPdBoICW9B6ja4+i3oP8Va32kgDLkW4m+BL+6CT2bC1itg4v9A\nRC97no+HaBaJ/omvtrH9cF6j7rN/51Aeu3xArdvdfffdDB48mIceeqjS8nvuuYeZM2cyc+ZM3nzz\nTe69916++OLUFsTHH3/Mzz+fnP1u1apVldYXFRWxevVqXnjhhXo+E6WaqfxUKxkXpINvIPgEQsZu\nKMoBvzbQY4J1C2AckJ0Emz6EtcfA2x+ufR96Tzp1vx37w22LYMXzsPwZ2PGV9WEw7gGIGuzOZ+gx\nmkWit1NoaCg33XQTL774IoGBgSeWr1q1innzrKlNZ8yYccoHQYXp06fz8ssvn7J87969DB06lP37\n93PZZZcxeHDrfAOqFih1m9UaH3YD+AVXv40x8OVv4PAG6HMJlBZB2XHofbGVlHucD74Bpz7O4YCc\nJPAJgNDONcfg7QPn/gGGz4RfXoE1/4HtX0CbzhDewzpp23uSdexWoFkk+rq0vJvS7373O4YPH86v\nf/3rRttnRY0+IyODs88+m/nz53PFFVc02v6VcquiXNj4AWx8H45usZYdXAXT3oTquu6ueR0SF8Kl\nz8Co2+t+HC8vCIur+/YhkXDBY3D2fSdjy0yEbfNg3Vsw+Tmr1NPC6cnYOggLC+Oaa67hjTfeOLHs\nrLPO4qOPPgLg/fffZ9y4cfXad0REBE8//TR///vfGyVWpdyuKA/euhS+fwTEGy75J5z7kJVMV750\n6vap2+HHv0CvSTDyNvfEGNgOxt4NV70Gty2EP+yxjv/1/ZDwpntisJEm+jp64IEHKvW+eemll3jr\nrbcYPHgw7777bo019o8//rhS98qVK1eess2VV15JYWEhP/30U5PFr1STKC+16uxpO+C6j+GOZTD6\nDjjvj1YJZuFjsG/pye1Li2De7RAQClNerr617w4+/jD93VaT7D1iztj4+HhTdeKRHTt20K9fP5si\nap30NVdnxBiYfw9seBeueAmG31R5fXE+/PcCOJZmnQg9uAqSfrLKPNd/Ar0vsiduV2XF8PEM2PMD\nzPwaYuv3zdwuIrLOGBNf23baoldK1c9P/2sl+XF/ODXJA/i3gWs/sLpI/vgnqz7e7wrPSfJgteyv\neRtCo60YHQ67I2oStZ6MFZE3gclAmjFmoMvye4C7gXLgG2PMQ87ljwK3Opffa4z5oSkCV0rZaNf3\nsPhJGHQNnP/nmrcL7wF3rQBTDu1j3BbeGfENhIl/gc/vgK2fwuBr7I6o0dWlRT8HuNh1gYicB0wB\nhhhjBgDPOJf3B64FBjgf84qIeDdmwEopm2Xth89nQafBVsmmtjp7u66em+QrDLrGej6L/mqdR2hh\nak30xpjlQFaVxXcBTxtjip3bpDmXTwE+MsYUG2P2A4nAqEaMVyllp9IimOss01zzTvV93ZsjLy+4\n6EnITYY1/7aW5STD3JnwyllwPNve+BqovjX63sA4EVktIstEZKRzeRcg2WW7FOeyU4jILBFJEJGE\n9PT0eoahlHKr7x6Eo5vhqtchrIVNUhM3AXpeCMv/FxbPhpdHwu4fIH0nfP+o3dE1SH0TvQ8QBowB\nHgTmyhkOaG6Med0YE2+MiY+MjKxnGEopt9n1Pax/x+pB0+fi2rdvji78K5Tkw/J/WieMf7vWer6b\nPoSd39odXb3VN9GnAPOMZQ3gACKAQ0BXl+2incuanaSkJAYOHFhp2eOPP84zzzxz2sclJCRw7733\nAlBcXMwFF1zA0KFD+fjjj5ssVoCYmBgGDRp0or9+RQw333wzsbGxDB06lCFDhrBo0aImjUO1YFs+\ngaAImPBHuyNpOh37WyWpmV9bt+26wrkPQqdB8NV9UFi1it081HcIhC+A84AlItIb8AMygPnAByLy\nLNAZ6AWsaYxAm4v4+Hji461urRs2bABg48aNdX58eXk53t71O3+9ZMkSIiIiTln+r3/9i2nTprFk\nyRJmzZrFnj176rV/1YqVl8KeBdDv8pY/sUe/yyvf9/GzhkJ+fYI19v205ndxVa0tehH5EFgF9BGR\nFBG5FXgTiBORrcBHwExn634bMBfYDnwP3G2MKa9p383ZhAkTePjhhxk1ahS9e/c+cVXr0qVLmTx5\nMmlpadx4442sXbuWoUOHsnfvXhYtWsSwYcMYNGgQt9xyC8XFxYDVGn/44YcZPnw4n3zyCRMmTOD+\n++8nPj6efv36sXbtWqZOnUqvXr34859P05WtFmPHjtXhkFX9HFgBxbnQ91K7I7FHp4Ew4WHY+hl8\ncbd1orYZqfWj2RhzXQ2rbqxh+9nA7OrW1dt3j5wcKKmxdBoElzzdoF2UlZWxZs0avv32W5544gkW\nLlx4Yl2HDh3473//yzPPPMPXX39NUVEREyZMYNGiRfTu3ZubbrqJV199ld/97ncAhIeHs379egBe\ne+01/Pz8SEhI4IUXXmDKlCmsW7eOsLAwevTowf333094ePgp8Zx33nknvg3MnDmT+++/v9L677//\nniuvvLJBz1m1Uju/tUaMjJtgdyT2Oft+OJ5jDci2ZS6MuNkq64R0sDuyWumVsTWo6dyy6/KpU6cC\nMGLECJKSkk67v127dhEbG0vv3r0BKxEvX778xPrp06dX2r5iJMtBgwYxYMAAoqKi8Pf3Jy4ujuTk\n6lsTS5YsOTGTlWuSf/DBB+nduzfXX389Dz/88GnjVOoUxsCu7yDuvJqHHW4NvH1g0my4Zz0MuQ7W\nvmEN8VBb3X7nN9ZVxDZqHsW2Bra86yM8PJzs7Mp9Z7OysoiNPdmlzN/fH7BmiSorK2vQ8YKDK/8D\nVezby8vrxO8V98/0WBU1+pdeeolbbrmFdevWNShW1cqkboXcg9b47so6QXvFizDsRpgz2bquYMbn\n4O176rbZSfDZ7VBeAmPvser9NtAWfQ1CQkKIiopi8eLFgJXkv//+e84555x67a9Pnz4kJSWRmJgI\nwLvvvsv48eMbLd66+O1vf4vD4eCHH3RUCnUGdn0HSKuZpKPOuo6Cy1+wBmr7oZqeSA6HVc8vLQBH\nqdUf3yaa6E/jnXfe4cknn2To0KGcf/75PPbYY/To0aNe+woICOCtt97i6quvZtCgQXh5eXHnnXc2\narznnXfeie6VN9106iBTIsKf//xn/vnPfzbqcVULt/MbiI5vFrVotxt6HYz9rVW3Xzen8ro1r8OB\nn+EcZxn1yCa3h1dBhylWJ+hrrk6Rewie6w8TH4Nxv7c7Gs/kKIf3r4Z9S6D3JdaMVe27w2vjrGGP\nr/sInu4GQ6+HS//VqIeu6zDFzaNGr5Syx+7vrNs+rbRbZV14ecPVc+DnZ2H9u7DrG/DysU5cX/6i\ntb7TIDiy2b4QbTuyUsrz7fzWmqM1so/dkXi2gFC44HH4/Xb41RvQYyJc+SqERlnrOw22uog77Lms\nyKNb9MaYGrs5qsblCSU85WEKs2D/MmuuVf0/rBsffxg0zfpxFTUY1hRA1j6I6OX2sDy2RR8QEEBm\nZqYmIDcwxpCZmUlAQAsZclY1jp1fg6MMBky1O5LmL2qIdWvTCVmPbdFHR0eTkpKCDmHsHgEBAURH\nR9sdhvIkW+dB+9iTSUrVX2Rf8PazEn3V1r4beGyi9/X1rXRxklLKjQoyYP9yOPs+Lds0Bm9f6NDf\nGsvfBh5bulFK2WjHfGue14Fatmk0UYOtFr0N5WhN9EqpU237HMJ7QseBtW+r6qbTYGtKwtwUtx9a\nE71SqrJjaZD0s3USVss2jSdqqHVrwwlZTfRKqcq2fwnGAQOusjuSlqXjABAvW+r0muiVUpVt+8Lq\nJdKxv92RtCx+QRDey5YrZOsyw9SbIpLmnE2q6roHRMSISITLskdFJFFEdonIpMYOWCnVhDISrdmk\ntDXfNKKGeGzpZg5wypTvItIVuAg46LKsP3AtMMD5mFdEpH4ToCql3Ku8FObdBgFtYfhMu6NpmaIG\nQ/5hOObe64NqTfTGmOVAdVOoPAc8BLj2FZoCfGSMKTbG7AcSgVGNEahSqokt/Tsc3mBNqlExRotq\nXNHOdPjvc60pUg/+Yo1b38TqVaMXkSnAIWNM1e8gXQDXee5SnMuq28csEUkQkQS9+lUpmyWtgJ+e\ntWZN6j/F7mharm6j4Zp3oPMwSHgT3pwEc2c0+WHP+MpYEQkC/ohVtqk3Y8zrwOtgjUffkH0ppRrg\neA58fgeExcLF/7A7mpav/xTrpygPdn8P/qFNfsj6DIHQA4gFNjlHlowG1ovIKOAQ0NVl22jnMqWU\np1rwP5B3GG5dAP4hdkfTegSEwuBr3HKoMy7dGGO2GGM6GGNijDExWOWZ4caYo8B84FoR8ReRWKAX\nsKZRI1ZKNZ4jm2D9OzDmLogeYXc0qonUpXvlh8AqoI+IpIjIrTVta4zZBswFtgPfA3cbY+wZaV8p\ndXrGwPePQlAYnPug3dGoJlRr6cYYc10t62Oq3J8NzG5YWEqpJrf9S6vP/OTnILCd3dGoJqRXxirV\nGpUehx//Yg1apn3mWzyPHY9eKdVEinKtrpS5B+HKr6zJq1WLpoleqdYgeQ2sfMk6+ZpzwFrWfwrE\nnmtvXMotNNEr1ZLlp8LCx2HTBxAcCTHnwPCboNMgiDvP7uiUm2iiV6ql2vE1fHGXVY8/534Y9wft\nJ99KaaJXqqVa8jdoEwXXfgARPe2ORtlIe90o1RLlHYG0bTD0Ok3yShO9Ui3SviXWbY+J9sahPIIm\neqVaosRFENxBJ/dWgCZ6pVoeh8Nq0fc4D7z0X1xpoleq5Tm6CQoztWyjTtBEr1RLs3exddtD+8kr\niyZ6pZqzwizYt6zyssTF1gVRIR3siUl5HE30SjVXKevgtXHwzhXWtHQAxfmQvFrLNqoSvWBKqebG\nGCuxf/8ItOkEMePgmz9A+1goKwJHKfQ43+4olQfRRK9Uc/Ptg7D2P9DzQpj6Onj5OCeZnmlNPu0b\nBN3G2B2l8iB1mWHqTRFJE5GtLsv+JSI7RWSziHwuIu1c1j0qIokisktEJjVV4Eq1aJl7Yee3py7f\nPNdK8mN+A9fPtWaHCgiF6z4CHz/Y86M1cJmPv/tjVh6rLjX6OcDFVZYtAAYaYwYDu4FHAUSkP3At\nMMD5mFdERAe7VupMGAPzZsFH18HKl08uzz4A3zwA3cbCRU9V7iPfvrs1po1PIPSd7P6YlUery1SC\ny0UkpsqyH13u/gJMc/4+BfjIGFMM7BeRRGAU1pyzSqm6OLgKDiVAu+7w45+s1vmIX1vJH+Cqf1c/\nWUjXUfDQXqt0o5SLxuh1cwvwnfP3LkCyy7oU57JTiMgsEUkQkYT09PRGCEOpFmLFixAUDnf+BL0v\ngW//AB9cDcm/wGX/a7Xea+IXDCLui1U1Cw1K9CLyJ6AMeP9MH2uMed0YE2+MiY+MjGxIGEq1HOm7\nYPd3MPJ2CGgLV8+xetDsXQyDrobB19gdoWqG6t3rRkRuBiYDE40xxrn4ENDVZbNo5zKlVF2sfAl8\nAmDU7dZ93wCY/j5s+QQGTrU3NtVs1atFLyIXAw8BVxhjCl1WzQeuFRF/EYkFegFrGh6mUq1A/lHY\n/DEMuxGCI04u9wuCETPBv419salmrdYWvYh8CEwAIkQkBXgMq5eNP7BArHrgL8aYO40x20RkLrAd\nq6RztzGmvKmCV6pFWf0aOMpg7N12R6JamLr0urmumsVvnGb72cDshgSlVKuz/UtY/W/odzmExdkd\njWphdKwbpexUXgY//hnm3gQd+sPF/7A7ItUC6RAIStnleDZ8PAOSfoKRt8Gkv+kVrapJaKJXyi6L\nn4IDK60LoIZca3c0qgXT0o1SdsjcC+vmwIibNcmrJqeJXik7LH4SvP1h/MN2R6JaAU30SrnboXWw\n7XM467fQpqPd0ahWQBO9Uu5kDCx4DIIiYOxv7Y6m2fjXDztZtTfT7jCaLU30SrlT4iKrl834h6xx\n5FWttqTk8n9L9vLGz/vsDqXZ0kSvlDv99L/W8MMjfm13JM3Gh2sPArB6XxZl5Q6bo2meNNEr5S55\nh+HgShg2w5oNStWqoLiMLzccomOoP/nFZWw+lHva7d/75QBfbz7spuiaD030SrnL9i+t2wFX2huH\nhyp3GE4OhGv5atNhCkrKeerKQQCs2JNR4+MdDsM/v9/Jsz/ubtI4myNN9Eq5y7YvoONAiOhldyQe\n6fdzN3L5yz+Te7z0xLIP1ybTu2MIF/TrQP+oUFbsrTnR700/Rl5RGfsyCjiYWVjjdq2RJnql3CHv\nsDVDVH9tzVfnaG4RX206zNZDedz13jpKyhxsO5zLpuQcrh3ZDRHh7J7hrD+Qw/GS6gfETTiQfeL3\nZXt01jpXmuiVcgct25zWvA0pOAzcO7EXK/dm8ui8LXy45iB+Pl5MHW7NRnpWzwhKyh0kHMiqdh/r\nDmQTFuxH17BAlu3SRO9Kx7pRyh20bFMjYwyfJKQwKiaM31/YGy+B5xfuQQSuHNqFdkHWietRMWH4\neAkrEjMZ1+vU6UfXHchmeLf2RLUN4LP1KZSUOfDz0bYsaIteqaanZZsTjDHkFpZWWrbuQDb7Mwq4\nOj4agPsm9mLaiGiMgetHdzuxXbC/D8O6tWNlNXX6zGPF7M8oYET39ozvHUlhSXmNLf/WqNZELyJv\nikiaiGx1WRYmIgtEZI/ztr3LukdFJFFEdonIpKYKXKlmQ8s2J/x7+T5Gzl7Imv0nk/DchGSC/Ly5\ndFAUACLCP341mIW/H8/ImLBKjz+rRwRbDuVW+2EBEB/TnrE9wvH1Fpbt1vJNhbq06OcAF1dZ9giw\nyBjTC1jkvI+I9AeuBQY4H/OKiHg3WrRKNUdatjnhy42HKSl3cMe7CRzILKCwpIxvNh/hskFRBPuf\nrCR7ewk9O4Sc8vize0ZgDKzaV3k4hHUHs/H1FgZ1aUuwvw8jY8K0Tu+i1kRvjFkOVP0ONAV42/n7\n28CVLss/MsYUG2P2A4nAqEaKVanmR8s2JyRnFbLjSB43jO6GAW59O4GP1iRTUFLONSO71mkfQ7u2\nI9DX+5TyzbqkbAZ2aUuAr9WuHN87kp1H80nNK2rsp9Es1bdG39EYc8T5+1GgYgi+LkCyy3YpzmWn\nEJFZIpIgIgnp6frJq1qorfOs24FT7Y3DAyzYngrAbePiePWGESRlFPDXr7cTGxFMfPf2tTza4ufj\nxajYMJbtTj8xHEJxWTmbD+VW2sf4PtbJWi3fWBp8MtZYl7KZWjc89XGvG2PijTHxkZGnnkFXqkXY\n+hlEDYXwHnZHYrsF21Pp1SGE2IhgxvYIZ/ZVAwG4Jr4rIlLn/Uwf2ZUDmYW8unQvAFsP5VFS5mCE\nS6Lv07ENHUP9NdE71bd7ZaqIRBljjohIFJDmXH4IcP0OFu1cplTrk7kXDq+Hi56yOxLb5RSWsCYp\nizvHx51YNn1kN4Z1a0+PyFNr8adz6aAoLh/SmRcW7WFCnw6sd56IHdH95IlbEeHcXpH8sO0oZeUO\nfLxbdwfD+j77+cBM5+8zgS9dll8rIv4iEgv0AtY0LESlmqmKss2Aq+yNwwMs3plGucNwYf9OlZb3\n7tgGb68sW3orAAAgAElEQVS6t+YrPDllAOEhfvzu4w2s2JtB9/AgIttUnlj9wv4dySsq01Y9dete\n+SGwCugjIikicivwNHChiOwBLnDexxizDZgLbAe+B+42xlR/vbJSLd3Wz6DbWdA22u5IbPfjtlQ6\nhvozuEvbRtlfuyA/nrl6CHvTC1i6K50R3U6t8Z/XtwMRIf58uCa5mj20LnXpdXOdMSbKGONrjIk2\nxrxhjMk0xkw0xvQyxlxgjMly2X62MaaHMaaPMea7pg1fKQ+Vug3Sd+hJWKCotJzle9K5oF9HvOrR\neq/JuF6RzBzbHYDh1ZzM9fX2YtqIaJbsSmv1vW9ad+FKqaay9TMQb+1WCaxIzKCwpJyLBnSqfeMz\n9Mgl/Xj44r5cMbRzteunj+xKucPw6bqURj92c6KJXqnGZoyV6OPGQ4j2KFuwPZUQfx/GxIXVvvEZ\nCvTz5q4JPQgN8K12fWxEMGPiwpibkIzDccadA1sMTfRKNbZD6yA7CQZOszsSj/DTngzG9YrA38ee\ni+SvHdmNA5mF/LKv9U4uroleqca26SPw9od+k+2OxHbHiss4lHOcgY10ErY+Lh7YidAAHz5a23pP\nymqiV6oxlRTC5rnQfwoE2JfcPMXetGMAZ9xXvjEF+HozdXg03289SnZBiW1x2EkTvVKNafsXUJwL\nI2bWvm0rkOhM9NUNUOZO00d2paTcwVetdOJwTfRKNaZ1b0N4T+h+tt2ReITE9GP4egvdw4NsjaNf\nVChxEcEs3plW+8YtkCZ6pRpL2g5rpMoRN8MZjN3Sku1JPUZMeDC+HjAEwYQ+HVi1N5Oi0tZ3Daf9\nr75SLcW6t8HLF4ZcZ3ckHmNv+jF6dbS3bFNhQp9Iisscp4xl3xpooleqMZQWwaYPod/lEBxhdzQe\noai0nAOZBfS08USsq1GxYQT6erO0FZZvNNEr1Rh2zIeiHKtsowBIyizAYaBnxzZ2hwJYvW/O6hHO\nkl3pWKOrtx6a6JVqDOvfgfaxEDPO7kg8xokeNx7SogerfHMwq5D9GQV2h+JWmuiVaqiyEjj4C/S/\nArz0X6rCntRjiEBcZLDdoZwwoU8HAJa0svlk9V2pVEOl7wBHKUQNsTsSj5KYfoxuYUEn5nH1BF3D\ngugRGczSXa2rTq+JXqmGOrLZuu2kid5VYuoxjyrbVDivTwdW78uisKTM7lDcRhO9Ug11dDP4hUBY\nXO3bthJl5Q72ZxTQ00O6Vrqa0KcDJeUOVia2nm6WDUr0InK/iGwTka0i8qGIBIhImIgsEJE9ztu6\nTe+uVHN1ZDN0HKj1eRfJ2ccpKXd4ZIt+ZGx7gvy8Wbq79ZRv6v3OFJEuwL1AvDFmIOANXAs8Aiwy\nxvQCFjnvK9UyORyQuhWiBtsdiUfZk5oP2D/GTXX8fbw5p2cEP2xLpaTMYXc4btHQJogPECgiPkAQ\ncBiYArztXP82oFPsqJYrax+UHINOmuhdJaZ7xmBmNbludDfS84v5Zou9g5zd++EGnl2wu8mPU+9E\nb4w5BDwDHASOALnGmB+BjsaYI87NjgIdq3u8iMwSkQQRSUhPb11dnVQLcnSTdast+koS047RKTSA\nNjXM/GS38b0i6dkhhDd+3m/bxVPGGJbuSiOroLjJj9WQ0k17rNZ7LNAZCBaRG123MdYrWO2raIx5\n3RgTb4yJj4zU6dZUM3VkszW+TWQ/uyPxKIlpnjPGTXW8vIRbzo5l66E8Vu/PsiWG7MJS8orKiI1o\n+tepIaWbC4D9xph0Y0wpMA84C0gVkSgA523rOeOhWp+jm6FDX/DxszsSj2GMITHtmK2TjdTF1OFd\naB/kyxs/77fl+PszrPJWXETTX1DWkER/EBgjIkEiIsBEYAcwH6iYdWEm8GXDQlTKQxljtei1/3wl\nh3OLKCwp99j6fIUAX29uHNOdhTtSSbJhSIR96dYx3XHlcENq9KuBT4H1wBbnvl4HngYuFJE9WK3+\npxshTqU8T/4RKMzQ+nwVu47mAdDbQwYzO50ZY7rj4yXMWZnk9mPvyyjA11vo0i6wyY/VoF43xpjH\njDF9jTEDjTEzjDHFxphMY8xEY0wvY8wFxhh7CmBKNbUTV8Rqone18WAO3l7CwC6hdodSqw6hAVwx\npAtzE5LJPV7q1mPvTy+gW1gQPm6YlEWv8FCqvo5uBgQ6DbQ7Eo+yITmHPh3bEOTnY3codXLjmG4U\nlpSzeGeqW4+7P6PALSdiQRO9UvV3ZJM17IG/55co3MXhMGw8mMOwbu3sDqXOhkS3IyLEj6VuHNHS\n4TDszyxw28iemuiVqq+jm7U+X8Xe9GPkF5cxrFvzGfnEy0s4t3cky3anU+5wT5/6QznHKSlzuKXH\nDWiiV6p+jmdDzkGtz1exITkHgKFdm0+LHqwRLXMKS9mUkuOW41VMfBKriV4pD7ZvmXWrY9BXsuFg\nDqEBPm5rqTaWcb0i8BLcNp/siUSvpRulPFRZMSx6AiJ6Q+y5dkfjUTYczGZot/Z4eYndoZyRdkF+\nDO/W3m0zT+3PKCDE34fIEH+3HE8TvVJnavW/rcHMJv0dvD1zLBc7FBSXsTs1v9mVbSpM6BPJlkO5\npOc3/dgz+zIKiI0IxrrWtOlpolfqTBxLh+X/gl4XQa8L7I7Go2xOycVhaFY9blxVzCe7bHfTt+r3\npR9zW30eNNErdWYWPwmlhTDpb3ZH4nE2JGcDMDS6eSb6AZ1DiWzj3+TzyRaVlnMo57hbJ03XRK9U\nXR3ZDOvfgVGzIKKX3dF4nA0Hc4iNCKZ9cPMc4E1EmNA7kuW70ykrtyYkOVZcxtHcogbt1xhDafnJ\nCU4OZhVijPt63IAmeqXqprwMvr4fAtvD+IfsjsbjGGPYcDCHYc20Pl9hQp8O5BWV8cm6FP70+RZG\nz17IBc8uI7+o/sMjPD5/G5OeX87xknLAZTAzN10VC5rolaqbn5+DQwlw2TNWsleVHMo5Tsax4mZb\nn69wTq8IvL2ER+dt4ZN1KYyKDeNYcRkLttdveIS96cd495cD7Esv4L8/7QNOdq2MiQhqtLhr0zwG\no1DKToc3wLKnYeA0GPgru6PxGN9tOUJJuYP+UaFsO2yNWDm0a/P+EGwb6Mvjl/enuMzBtBHRhAb4\ncs4/FvP15iNMHR59xvt7cdEe/H28Gd69Ha8u28v0UV3Zl36MyDb+bp19SxO9UqdTehzmzYLgDlZr\nXgGQkl3IXe+vr7TM38eLvlHNf9yfGWNjKt2fPKQzb/68n5zCEtoF1f38w+7UfOZvOswd5/bg2pFd\nufC5ZTz74272ZxS4/YIyTfRKnc7CJyBjN8z4XEs2Ln7YZpUy3rp5JNmFJWw/nEf3iGB83TDkrrtN\nHhzF68v38cO2o0wf2a3Oj3t+4W6CfL2549w42gf7MXNsDG+s2I+/jxdXDevShBGfShO9UjXJPgCr\nX4ORt0GP8+2OxqP8sO0ofTq24by+Vt/zqcNtDqgJDerSlu7hQXy9+UidE/32w3l8u+Uo95zf80Qv\npHvO78Wn61PIKSx1a48baGCiF5F2wH+BgViTgN8C7AI+BmKAJOAaY0x2g6JUyg6bPrRuz77P3jg8\nTMaxYhKSsvjteT3tDsUtRITJg6N4deleMo4VE1Fl2IKC4jIW70wjISkLH28vAn29WbE3gzYBPtx2\nTtyJ7doG+fK7ib14/Kvtbp9msaEt+heA740x00TEDwgC/ggsMsY8LSKPAI8ADzfwOEq5l8MBG96H\nuPHQru5f1+1QVu5wyyxFFRZuT8VhYNLATm47pt0uH9KZ/1uyl++2HmXGmO4ALN+dzgerD7JkVxrF\nZQ6C/bwBOF5ajsPAo5f0pW1Q5ROuM8bGEN0+iPG9O7g1/nonehFpC5wL3AxgjCkBSkRkCjDBudnb\nwFI00avmJuknyD0IE//H7khqlFtYyiPzNvPLvkx+vH88kW3cM0DWD9uOEt0+kP5Rnj9VYGPp07EN\nPTuE8NWmw0wa0JEnvtrON5uPENnGn2tHduXSQVHEx4Th7SUYYyhzmGrPV3h7CRf07+j2+BvSoo8F\n0oG3RGQIsA64D+hojDni3OYoUO2zEpFZwCyAbt08u8WkWqGN74N/W+g32e5IqrX+YDb3fLCB1Lwi\nyo3hnVVJPHBRnyY/bn5RKSsSM5kxtrvbBuTyBCLC5YM78/yi3Uz832UUlzl44MLe3DG+B34+Xqds\n6+vtWa9NQxK9DzAcuMcYs1pEXsAq05xgjDEiUu2ULcaY14HXAeLj490zrYtSdVGUC9u/hKHXg2+g\n3dFQVFrOC4v2cKyoDIDCknK+3HiITm0D+OTOsby2bC/vrDrAneN7EOzftP0rluxKp6TcwaQBrads\nU+GKoZ35vyWJDOzcltlXDSQu0r119oZoyLsiBUgxxqx23v8UK9GnikiUMeaIiEQB7hnJX6nGsnUe\nlBXBsBvtjgSwasGvLt1L20BfvJ3jvF86KIonrxxI20BfZp3bgx+2pTI3IZlfnx3bpLH8sO0oESF+\njOje+rqaxkYEs/ZPFxAa6NPsvs3UO9EbY46KSLKI9DHG7AImAtudPzOBp523XzZKpEq5y4b3ILIf\ndPaMPoPrDmTj5+3F6j9OJMDX+5T1I7q3J757e974eT8zxnRvshOzRaXlLN2ZxhVDO5/4wGltqp5c\nbS4a+o64B3hfRDYDQ4G/YSX4C0VkD3CB875SzUPaTmtMm2E3gIe02tYmZTEoum21Sb7CrHPjSMk+\nzrdbjzZZHAu2p1JQUs5FrbBs09w1qKBnjNkIxFezamJD9quULcqKYf494BsEg6fbHQ1gtaK3HMrl\nllpKMhf060hcZDCvL9/L5YOjGr20cDCzkD9/sZW+ndpwdo+IRt23anot73plperDGPjm95CyBq58\nBULc28+5JptTciktN8THhJ12Oy8v4fZxcWw9lMfKvZmNGkNhSRmz3k3AGMO/Z4w4pZeJ8nz6F1MK\nrHlgN7wH5z4EA66yO5oTEg5kAdTp5OdVw7oQEeLHf5zD4dbFntR87n5/PZOeW85/f9pHXpVx140x\nPPLZFnal5vPidcPoHu7eS/dV49CxbpTatxR++CP0nQwTHrU7mkoSkrLpERlMWB1mbQrw9eamsTE8\nu2A3u1Pz6d2x5pEkk7MKeW7Bbj7feIhgPx96dgjhqW928PzCPfxqeBci2/hTVOrgYFYh8zcd5sFJ\nfU7MqaqaH030qnU7ngOf3Q4RveGq18DLc77kOhyGhKQsLh0UVefH3DimO68sTeS/P+3jn9OGVLtN\nUWk5V72ykmPFpcwaF8cd43sQFuzHlpRc3vh5H++vPkiZw+Al1ofHNfHR/GZCj8Z6WsoGmuhV67b4\nKSjMgBvmgr9njaWemH6MvKKyWuvzrsKC/Zg2Ipq5a1P4w6Q+dGgTcMo2X28+QsaxYt67dTTn9Dp5\nYnVQdFuev3YYT/9qMF7OqzubW39xVT3Pab4o5W6H1sPa/8LI26HzMLujOcXaJKs+H3+GFyfdek4c\npQ4H7646UO36d1cl0bNDCGf3DK92fYCvN34+XprkWxBN9Kp1cpRbk32HdIDz/2R3NNVal5RNRIg/\n3cPPbG7R2IhgLujXkfd+OXBiQuoKm5Jz2JSSy4wxrWusmtZOE71qOYyBvCO1bweQ8CYc2QiT/gYB\nbZs2rnpaeyCL+O7t65WQbx8XR3ZhKZ+uT6m0/L1fDhDk581Vw907w5GylyZ61TIkr4E3LoJn+8Li\n2VbSr47DAVs+hUV/hbgJHjvZd2peEclZx4mPqd+YMiNj2jOkazueW7CbrYdyAcguKGH+psNcOawL\noW6cmFrZTxO9at5ykuGTm+GNCyHnAPS+BJb/Ez67FUqLTm5nDOz8Bl47x1rXNhomP+8xwxxUlZBk\nTco28gxOxLoSEZ67ZggBPl5c9/ovrN6XyafrUiguc5yYOEO1HtrrRjVf5WXw/tVWgh//CJx1D/gF\nw4oXYOFjkHMQ+lwCyWshZa3VuyasB/zqDRgw1aO6UlZIzirk8w2H+HhtMkF+3vTvXP/JPeIiQ/j0\nrrOY8cZqbnpzDW0CfBkZ055+rWjCEGXRRK+ar4Q3IX0HTH+/8gQh5/wOwmJh3h1Wgg/vBb0nWaWa\nAVPB2/Pe9mXlDn77wQa+32YNSjY2Lpy/Tx1U7SxFZ6Jzu0A+ufMsbn5rDZtTcvnL5H6NEa5qZjzv\nHa9UXRRmwdK/Qey50PeyU9f3nwIx46zfg+pX/nCnOSuT+H7bUe44N44ZY7sT3f7MetqcTliwHx/c\nPoaf96RzUX8debI10kSvmqelT1szQV38dM119maQ4AGO5B7nuQW7mdAnkkcu6dsk3R5D/H24eGDd\nr7BVLYvnFSmVqk3aTutCpxE3Q8cBdkfTYE9+vZ0yh+GvVwzUvu2qSWiiV82LMdYAZH4hcJ5nXuh0\nJpbuSuPbLUe55/yedDvDC6OUqqsGJ3oR8RaRDSLytfN+mIgsEJE9ztvWN7mkajqJi2DvIpjwMAQ3\n7wkw8opK+Z8vtxEXGczt58bZHY5qwRqjRX8fsMPl/iPAImNML2CR875SDecohwV/gfYx1vg0zVC5\nw/Dzngzu/3gjo2cvIjm7kKemDMTfp+ZpApVqqAadjBWRaOAyYDbwe+fiKcAE5+9vA0uBhxtyHKUA\n2PgBpG2HaW+BT+3js3ua0nIHN7+1hhWJmbQJ8OHKYV2YPrIrQ7u2szs01cI1tNfN88BDgOv4rh2N\nMRUDjhwFOlb3QBGZBcwC6NatWwPDUC1eSQEsmQ1d4j1qBqgzMfubHaxIzOQvk/tzw+hup53sW6nG\nVO/SjYhMBtKMMetq2sYYY4BqBx0xxrxujIk3xsRHRkbWNwzVWqx6BfKPwKTZHjtswenMW5/CnJVJ\n3HJ2LLeeE6tJXrlVQ1r0ZwNXiMilQAAQKiLvAakiEmWMOSIiUUBaYwSqWrFjabDieWuqv25j7I7m\njG09lMuj87YwJi6MRy/ta3c4qhWqd4veGPOoMSbaGBMDXAssNsbcCMwHZjo3mwl82eAoVevlKIcv\n74ayIrjgCbujOWO5haXc8e46woL9ePn64Q0e0kCp+miKd93TwIUisge4wHlfqfr58c+w50e45J8Q\n0dPuaM6IMYY/fr6F1LwiXr1xBBEh/naHpFqpRhkCwRizFKt3DcaYTGBiY+xXtXJr34BfXoExv4GR\nt9odzRn7bP0hvtlyhIcu7qM9a5St9Huk8kx7l8C3D0KvSXDRU3ZHc8YOZBbw2JdbGR0bxh3n9rA7\nHNXKaaJXnmfvYvjoBojsA7/6L3g1rx4qpeUO7vtoI95ewnPTh+Lt1fx6CamWRRO98izbvoD3r7Gu\nfp3xOQQ0v0ky3l6ZxMbkHP42dRCd2wXaHY5SmuiVB1k3Bz79NXQZAb/+Bto0v7HTHQ7D26uSGB0b\nxuTBne0ORylAE73yBCWF8PXv4av7oMdEqyUf2DzHwlu+J53krOPcqPOyKg+iE48oex3eAJ/dDpl7\nYOxvYeJjzXIcmwrv/XKQiBA/Jg1oft9GVMuliV7Zo7wUfn4elj0NwR3gpvkQN97uqBrkUM5xFu9M\n5c7xPfDz0S/LynNoolful7oNvrgLjmyyJuu+7H+bzbR/p/PxmoMY4LpROkif8iya6JV7rXgRFv0V\nAtrCNe9Yk3i3AKXlDj5am8x5fTrQNUxnilKeRRO9cp+Dq62JQ/pcBle82OxniHK1YHsqafnF3DBa\nW/PK82iiV+5hDCx6wqrH/+o/4Bdsd0SN6r1fDtClXSAT+nSwOxSlTqFnjJR7JC6CAytg/EMtLsnv\nSc1n5d5Mrh/dTa+CVR5JE71qeg4HLHoc2nWH4TNr3by5mbMyCT8fLz0JqzyWlm5U09v+ORzdAle9\n3qz7yFcn93gp89YfYsqQzoQFt6znploObdGrplVeCoufgg4DYNA0u6NpdJ8kJHO8tJyZZ8XYHYpS\nNdIWvWo6xlhdKbP2wXUfNbtRKGtT7hzXZlRMGAO7tLU7HKVq1JDJwbuKyBIR2S4i20TkPufyMBFZ\nICJ7nLfNc9AS1XDL/gErX4T4W6H3xXZH0+gW70wjOeu4tuaVx2tI6aYMeMAY0x8YA9wtIv2BR4BF\nxphewCLnfdXa/Pw8LP07DL0RLn0GpOX1Rpmzcj9RbQO4aEBHu0NR6rQaMjn4EWPMeufv+cAOoAsw\nBXjbudnbwJUNDVI1MwlvwsLHYOA068Ior5Z3KmjdgWxWJGZy45juOuG38niN8g4VkRhgGLAa6GiM\nOeJcdRSotrkjIrNEJEFEEtLT0xsjDOUJSgpg4eMQNwGueq3F1eUBkrMKuePdBKLbB+qVsKpZaPDJ\nWBEJAT4DfmeMyROXr+jGGCMiprrHGWNeB14HiI+Pr3abess/CslrrEGzMhMhcy9kJ4F/CIR2gdDO\n4N8GSo9bP37BMGl2s5zowuNsngtFuTDhUfD2PeOHG2PIKSzlaF4R3cKCCPb3rP4COYUlzHxrDaXl\nho9mjaJdkHapVJ6vQf9FIuKLleTfN8bMcy5OFZEoY8wREYkC0hoaZI0y9sB3D528bwxk7YWcg84A\nvaF9dwjvCd3HWhNc5KVA2g4rwfsGgE+g9WGQnQQ3f2Mta2mMgZQESNsGhVlwPAu8/WDk7RAa1bjH\nWf1v6DQYuo6udfNjxWWs2pvJjiN5bD+cx+7UfA7nHqeo1AFAl3aBvH7TCAZ0rnuPFmMMx4rLyCks\nJbuwhNLy6tsQ/j5e9I8KxesMrmQtLitn1rvrSMk6zru3jqJnh5A6P1YpO9U70YvVdH8D2GGMedZl\n1XxgJvC08/bLBkV4Oo5yKM6vvKzzcBh9J0SPhKgh4ONf+352fAUf3whf3w9XvtKkJw5LyhzuG6u8\nKA82f2zVzNO2n1zuE2D1b//lVTjrXjjrHuvbTjWOFZcR7OeN1OU12b8c0nfAlNO/hsYYvtt6lMfn\nbyMtvxgR6B4WRN9OoUzs14GotoG0CfDh2QW7mfbqKp65egiXDa7+A6m4rJxNybmsSMxg1d5MNqbk\nUFLmqD1W4ML+HXlu+lBCavnWYIxh6a50nl+0h03JObxw7VBGx4XX6RhKeQIxpn5VExE5B/gJ2AJU\n/Gf9EatOPxfoBhwArjHGZJ1uX/Hx8SYhIaFecTSapf+ApX9j/4g/sq7zDRQVFxGSvQP/klyOdxpB\nm7ZhtA/ypV2QH+2DfGkb6ItPNSfhjhWXkZxVSKfQANq7XCm54WA2/7ckkYU70hjWrR1Th0dz+eCo\nhn31Ly+DX16B3BTwDbR+yopOlqsyE6G8xPrAi78VepwPQeHgF2T1bV/4BGz/AkI6wpjfwLAbITgC\nh8OwdHca//1pPyv3ZhLs501MRDCxEcGEBp4sx/h5e9GpbQBRbQPo3C6QYSvvxidlNdy/vdpvRsYY\nDmYV8tevtrNoZxoDOofy6CX9GNatXbUlmrT8Iu56bz3rDmRz45hu9IwMIcDXG28vYdfRfNYfzGbr\n4TxKyhyIwKAubRkZE0an0ADaOf9WNX2obj2Uy7MLdtMjMpj/3BRP9/BTx98pKC5j8c40Xlu2l22H\n8+jcNoAHL+7DVcOi6/83U6oRicg6Y0x8rdvVN9E3pvom+rT8Ij5dl0KAjzcBvt4E+nnRLsiPzm0D\n6dQ2gNAAnzq1RBPT8vk0IZlRa+9nvGM1G01PBkgSAVIKQJnxYrOJY6VjACscA1nv6EUxfoQG+NA+\n2I92gb74+XhxILOQtPziE/uNiwhmWLf2pOYV8XNiBu2CfLliSGfW7M9i59F8/Ly9GBzdlrjIYGIj\nQujbqQ1je4QT4FuHE5hFefDpLZC4APzbWgm+vBi8fKB9rFWuiugJA64iPXQgO4/mERHiT7+o0Mr7\nObjauqjpwM8YLz8SIyfyRU4Pio9lE+1/nCGRQlm5g/yiUvKLyjhe7kURfhSLP8nl4cwtHk0JvkRL\nGsv87ueLkOkkD3uAyDb+HMkp4khuEUdyj3M0t+hEWSbQ15vfX9ibX58dU+2HpavisnIen7+ND9ck\nV1ru5+PFoC5tGdG9PSO6t2dMbDhtg87snMCKxAx+8/56AGadG0dogA8Bvt7kF5WxdHc6v+zNpKTc\nQUx4EL+Z0JMrh3XRmaOUR2kViX79wWymvrKyxvUdQ/3546X9uGJI50oJv7TcQUJSNot3prJoZxr7\n0gvw9hIu6hnCk8f/RhvvEso7j0C6jsIR2J6yvT/hc+AngtI3Iqacci8/DrUZzJ6gYWzyHcpmRyyF\n5V50CwsiNiKYbmFBJGcXsv5ADhsOZuPtJdw2LpYbRncn2N8HYwzbDufxxYZDbE7JISx9NdNKvmS4\n1x4O05GitrG07dKXrA6j2enTl8P55YgIcRHBxEYG08mkE/blDAJzE/m22x/42mcSR/KKSM0+RmGp\ngzaB/oQF+xHo583+jALSXT58+nZqw7QR0ZzbO5KjuUXszyhgT1o+ybvWMyH/G37l/ROhUgiA8fJB\n/ENP9pwxBhylUOr8UAEcoV3IGH4fRYe3E737XW5p9ybLUn0xBry9hI5t/K1Wf7tAokKt20kDOhLd\n/swm5ygqLed4STnHS8spKXPQuV1goyTdA5kF3PneenYcyau0PC4imPP7duD8vh0YHReuo1Iqj9Qq\nEr0xhuIyB8WlDo6XWkkgq6DYakXmFPH1liNsSs5hXK8IZl85iLyiUj5bn8L8jYfJLCjBz9uL0XFh\nTOzbgcsGdyayTS31/OJ8OLAK9i+DfcsgdYu13C8Euo6yRmcM7QJtu0DnYRDZl4pX95RvFuVlsPUz\nWPUSHN2CIyiCtE7jyUs7SPCxJKJMBl5iyDVB/GSGst90oo05Rns5xlleW/GnjLtK72Od9xCi2wcR\n1TaATqEBBPv7kHfcOhF5rLiMbmHB9O8cSr9ObdibfoxP1x9iU3JOpVCC/bwZFRvG+f06MrFHCJ19\n8iEwzOqZVNM3Ike5VZNf/CQcWmctG3AVXD2H3MJSjpeWE9nGv1kkSGMMBSXWB0nR/7d3byFW1XEU\nx9FTIlEAAATdSURBVL+r8T6Gms6Md53A1EG8RIR2kUofKk2jBysQJOhNyKIL1kv10EtEl4cIQgvD\nLoQJSZBUVmSQYqmgeSHxOuo4ZnjN0pxfD/8NcyayUatz5uy9PjDM2Xsfhj+LOWv2+e//PnP+AjVX\niaH9e1d6WGadKkTRd+ZCW7B83T5eXL2Ds+cv0BZpXnnG+HrmTBrKrdfVdXoh7h+dOQZ716bCa94A\nJw/Cr8faj9fWQ+P0tOJn8ESob0pLDje/B9++Asf3waCxMG0hTJyX5thJ7zi27G5m4JHvaGj5mp57\nvkBnWrnQsz+/d+/HqV5DODT1OQaPmUzD1b0ua+UIwK7W02w+cJwRA3rTWFdLXd+el3ax9e9EwM5P\nYeM7MPNZqB9/ZT/HzC6bi77E4RNnWbp2D6MG9uGeSUP/37XP53+DEwdg/7p05r/nGzh9JDuodPZ/\n7lRaHTT9yfQZMJ3dORoB0ZbLm4/M7Mq56LuKiFT8LVugZWt6POE+uPb2XH7+i5mVz6UWfde67TCP\nJOg/Mn2Nm1Xp0ZhZAXmtmJlZzrnozcxyzkVvZpZzLnozs5xz0ZuZ5ZyL3sws51z0ZmY556I3M8u5\nLnFnrKSjpM+uv1KDgJ//o+FUO2fRkfNo5yw6ykMeoyKirrMndYmi/7ckfX8ptwEXgbPoyHm0cxYd\nFSkPT92YmeWci97MLOfyUvRvVnoAXYiz6Mh5tHMWHRUmj1zM0ZuZ2cXl5YzezMwuwkVvZpZzVV30\nku6UtFPSLkmLKz2ecpM0QtJXkrZJ+lHSomz/NZI+l/RT9n1ApcdaLpJqJG2S9Em2XeQs+ktaIWmH\npO2SphU1D0mPZa+RrZLel9SrSFlUbdFLqgFeB+4CmoAHJTVVdlRl9wfweEQ0AVOBhVkGi4E1ETEG\nWJNtF8UiYHvJdpGzeA1YHRHjgEmkXAqXh6RhwCPADRExAagBHqBAWVRt0QM3ArsiYndEnAM+AOZW\neExlFRGHI2Jj9vgU6YU8jJTDsuxpy4B7KzPC8pI0HJgFLCnZXdQs+gHTgaUAEXEuIo5T0DxI/za1\nt6RuQB/gEAXKopqLfhhwoGS7OdtXSJJGA1OA9UBDRBzODrUADRUaVrm9CjwFtJXsK2oWjcBR4O1s\nKmuJpFoKmEdEHAReAvYDh4ETEfEZBcqimoveMpL6Ah8Bj0bEydJjkdbP5n4NraTZQGtE/HCx5xQl\ni0w34HrgjYiYApzhL1MTRckjm3ufS/rjNxSolTS/9Dl5z6Kai/4gMKJke3i2r1AkdSeV/LsRsTLb\nfUTSkOz4EKC1UuMro5uBOZL2kqbx7pC0nGJmAekdbnNErM+2V5CKv4h5zAT2RMTRiDgPrARuokBZ\nVHPRbwDGSGqU1IN0cWVVhcdUVpJEmoPdHhEvlxxaBSzIHi8APi732MotIp6OiOERMZr0u/BlRMyn\ngFkAREQLcEDS2GzXDGAbxcxjPzBVUp/sNTODdD2rMFlU9Z2xku4mzcvWAG9FxAsVHlJZSboFWAts\noX1e+hnSPP2HwEjSxz/Pi4hfKjLICpB0G/BERMyWNJCCZiFpMunCdA9gN/AQ6eSucHlIeh64n7RS\nbRPwMNCXgmRR1UVvZmadq+apGzMzuwQuejOznHPRm5nlnIvezCznXPRmZjnnojczyzkXvZlZzv0J\nH7p2Y4ggQcwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1178607f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And see the results\n",
    "def smooth(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "runs = {\n",
    "    'none': 'No ER',\n",
    "    'uniform': 'Uniform ER'\n",
    "}\n",
    "\n",
    "for er_type in runs:\n",
    "    plt.plot(smooth(run(er_type), 10))\n",
    "plt.title('Episode durations per episode')\n",
    "plt.legend([runs[er_type] for er_type in runs])\n",
    "\n",
    "# plt.plot(smooth(none_episode_durations, 10))\n",
    "# plt.plot(smooth(random_episode_durations, 10))\n",
    "# plt.title('Episode durations per episode')\n",
    "# plt.legend(['No ER', 'Vanilla ER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6bf6b7b7758e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Returns a Python scalar, and releases history (similar to .detach())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seed' is not defined"
     ]
    }
   ],
   "source": [
    "def train_true_gradient(model, memory, optimizer, batch_size, discount_factor):\n",
    "    \n",
    "    # don't learn without some decent experience\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "\n",
    "    # random transition batch is taken from experience replay memory\n",
    "    transitions = memory.sample(batch_size)\n",
    "    \n",
    "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
    "    state, action, reward, next_state, done = zip(*transitions)\n",
    "    \n",
    "    # convert to PyTorch and define types\n",
    "    state = torch.tensor(state, dtype=torch.float)\n",
    "    action = torch.tensor(action, dtype=torch.int64)  # Need 64 bit to use them as index\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float)\n",
    "    reward = torch.tensor(reward, dtype=torch.float)\n",
    "    done = torch.tensor(done, dtype=torch.uint8)  # Boolean\n",
    "    \n",
    "    # compute the q value\n",
    "    q_val = compute_q_val(model, state, action)\n",
    "    \n",
    "    target = compute_target(model, reward, next_state, done, discount_factor)\n",
    "    target = torch.autograd.Variable(target)\n",
    "    \n",
    "    # loss is measured from error between current and newly expected Q values\n",
    "    loss = F.smooth_l1_loss(q_val, target)\n",
    "\n",
    "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()  # Returns a Python scalar, and releases history (similar to .detach())\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "\n",
    "model = QNetwork(num_hidden)\n",
    "\n",
    "episode_durations_true_gradient = run_episodes(\n",
    "    train_true_gradient, model, memory, env, num_episodes, batch_size, discount_factor, learn_rate)\n",
    "\n",
    "plt.plot(smooth(episode_durations, 10))\n",
    "plt.plot(smooth(episode_durations_true_gradient, 10))\n",
    "plt.title('Episode durations per episode')\n",
    "plt.legend(['Semi-gradient', 'True gradient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
